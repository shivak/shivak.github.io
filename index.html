<html>
<head>
<style type="text/css">

* {
  font-family: sans-serif;
}

i {
  color: #333;
}

</style>
<title>Shiva Kaul</title>
<body>

<img src="mlhc-pic.png" style="float: left; width: 20%; min-width: 200px; margin-right: 1em; margin-bottom: 1em" />
<p><b>Shiva Kaul</b>. I'm a Ph.D student in the Computer Science Department at Carnegie Mellon. I work on <a href="https://dl.acm.org/doi/abs/10.1145/3278721.3278796">trustworthy machine learning</a>. 
Like most people, I've been pretty amazed by the recent advances in AI and ML; like most researchers, I'm kind of wistful for the clarity and understanding we had in traditional machine learning, and a bit concerned about how a lack of such understanding could potentially lead to bad, harmful decisions. But I'm optimistic: In my opinion, modern learning is not inherently inscrutable, and classical learning isn't merely relegated to the dustbin of history. I think by <a href="thesis-outline.pdf">nontrivially combining</a> classical models with modern ones, we can achieve the best of both worlds. For example, we can <a href="https://proceedings.neurips.cc/paper/2020/hash/c3581d2150ff68f3b33b22634b8adaea-Abstract.html">replace the guts</a> of RNNs or Transformers with linear systems, making them both faster and more mathematically tractable. Alternatively, we can wrap foundation models (such as LLMs) in Gaussian processes and conformal prediction, allowing them to reliably answer important causal questions. I've always been interested in applications to <a href="http://proceedings.mlr.press/v106/kaul19a.html">healthcare and wellness</a>. With these new techniques, I'm currently reexamining the foundations of evidence-based medicine. 

<p>My advisor is the razor-sharp, incredibly-patient <a href="http://www.cs.cmu.edu/~ggordon/">Geoff Gordon</a>. Earlier, I earned an M.S. under <a href="https://www.cs.cmu.edu/~satya/">Mahadev Satyanarayanan</a> on the topic of human-in-the-loop machine learning.

<h2 style="clear: both">Publications, reports, and working papers</h2>
<ul>
<li><a href="papers/conformal-meta.pdf">Meta-Analysis with Untrusted Data</a>. By Shiva Kaul and Geoffrey J. Gordon. <a href="https://ml4h.cc">ML4H 2024</a>. <a href="https://arxiv.org/abs/2407.09387">Full version</a>
<li><a href="https://openreview.net/pdf?id=XRo78JEfVnt">Optimizing Over All Sequences of Orthogonal Polynomials</a>. By Shiva Kaul. Working paper.
<li><a href="https://proceedings.neurips.cc/paper/2020/hash/c3581d2150ff68f3b33b22634b8adaea-Abstract.html">Linear Dynamical Systems as a Core Computational Primitive</a>. By Shiva Kaul. NeurIPS 2020. <i>Selected for Spotlight Presentation</i>. <a href="https://github.com/shivak/ldstack">Code</a> 
<li><a href="http://proceedings.mlr.press/v106/kaul19a.html">Measuring the Sympathetic Response to Intense Exercise in a Practical Setting</a>. By Shiva Kaul, Anthony Falco, and Karianne Anthes. <a href="https://www.mlforhc.org/2019-conference">MLHC 2019</a>.
<li><a href="#">Linear Dynamical Systems as a Core Computational Primitive</a>. By Shiva Kaul. <a href="http://roseyu.com/time-series-workshop/">ICML 2019 Time Series Workshop</a>.
<li><a href="papers/mo.pdf">Margins and Opportunity</a>. By Shiva Kaul. <a href="http://www.aies-conference.com/2018/">AAAI/AIES 2018</a>. <i>Selected for Doctoral Consortium</i>.
<li><a href="papers/soa.pdf">Depth Without Distress</a>. Working paper.
<!--<li><a href="proposal.pdf">Fast Agnostic Classification</a>. Ph.D thesis proposal.-->
<li><a href="https://sites.google.com/site/costnips/abstracts#shiva">Anticoncentration regularizers for stochastic combinatorial problems</a>. In <a href="https://sites.google.com/site/costnips/">NIPS 2011 Workshop on Computational Trade-offs in Statistical Learning</a>.
<li><a href="https://arxiv.org/abs/1311.3440">Using molecular similarity to reduce the cost of electronic structure calculations</a>. In Abstracts of Papers of the American Chemical Society (Vol. 244). 1155 16TH ST, NW, Washington, D.C. 20036 USA
<li><a href="http://reports-archive.adm.cs.cmu.edu/anon/2010/abstracts/10-120.html">Interactive machine learning in Diamond</a>. M.S. Thesis and CMU Technical Report, CMU-CS-10-120
</ul>

<h2>Selected recent talks</h2>
<ul>
<li><a href="talks/meta-sunlab-illinois.pdf">Meta-Analysis with Untrusted Data</a>. <a href="https://sunlab.org/">Sunlab</a>, University of Illinois, September 2024.
<li><a href="talks/neurips20.pptx">Linear Dynamical Systems as a Core Computational Primitive</a>. NeurIPS, December 2020. <a href="talks/neurips20-poster.pdf">Poster</a> and <a href="https://slideslive.com/38938000">Video</a>.
<li><a href="talks/allergan.pptx">Trusting Modern Machine Learning</a>. Allergan Scientific Series, January 2020.
</ul>

<p><a href="mailto:skkaul@cs.cmu.edu">Contact me</a>
</body>
</html>
